## 本地模式
- spark-submit --master：默认一个线程执行
- spark-submit --master local[4]：会有4个线程来并发执行
- spark-submit --master local[*]：尽可能多的线程
> 不需要启动spark或hadoop的服务。只会启动一个SparkSubmit的进程，同时是client、driver、executor。

## 本地伪集群
- spark-submit --master local-cluster[2, 3, 1024]：2个executor进程，3个core，1024MB
> 不需要启动spark或hadoop的服务。会产生一个SparkSubmit进程，和2个executor进程。SparkSubmit是client、driver。

## Standalone Client模式
- spark-submit --master spark://my-master-server:7077
- spark-submit --master spark://my-master-server:7077 --deploy-mode client
> 需要启动Master和Slave服务，不依赖hadoop服务。Worker节点上会启动executor进程，每个executor进程所使用的core和内存数量都是可以通过命令行参数设定的。SparkSubmit作为client和driver。

## Standalone Cluster模式
- spark-submit --master spark://my-master-server:7077 --deploy-mode cluster
> 需要启动Master和Slave服务，不依赖hadoop服务。提交应用程序的节点会有SparkSubmit进程，进程会在提交后退出。Master会选择就某一个Worker进程生成一个子进程DriverManager来启动driver程序。

## Yarn Client模式
- spark-submit --master yarn
- spark-submit --master yarn --deploy-mode client
> 在ResourceManager的节点上提交程序,并生成SparkSubmit进程,该进程执行driver程序。在某个NodeManager节点上启动ExecutorLauncher程序，作为ApplicationMaster。在多个NodeManager节点上执行executor进程。

## Yarn Cluster模式
- spark-submit --master yarn --deploy-mode cluster
> 在ResourceManager的节点上提交程序,并生成SparkSubmit进程,该进程`不`执行driver程序，提交成功后进程退出。在某个NodeManager节点上运行ApplicationMaster，ApplicationMaster同时会执行driver程序。在多个NodeManager节点上执行executor进程。

## driver程序是什么
> 执行main()，创建SparkContext。SparkContext负责和ClusterManager通信，进行资源的申请、任务的分配和监控等。